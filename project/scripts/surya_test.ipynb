{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# surya_batched_processing.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from pypdf import PdfReader\n",
    "import fitz  # PyMuPDF for rendering PDF pages to images\n",
    "\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "from surya.layout import LayoutPredictor\n",
    "from surya.table_rec import TableRecPredictor\n",
    "\n",
    "# --- Configuration ---\n",
    "PDF_PATH    = \"/Users/nicholasmcintosh/Documents/sandbox_code/project/data/raw/ANTI_OEDIPUS_FR.pdf\"\n",
    "BATCH_SIZE  = 10\n",
    "OUTPUT_DIR  = \"surya_batch_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Helper: Recursive serialization for Surya result objects ---\n",
    "def serialize_surya(obj):\n",
    "    if hasattr(obj, \"to_dict\"):\n",
    "        return obj.to_dict()\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [serialize_surya(item) for item in obj]\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        return {key: serialize_surya(value) for key, value in obj.__dict__.items()}\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Surya predictors...\n",
      "All Surya predictors initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Initialize Surya Predictors\n",
    "\n",
    "print(\"Initializing Surya predictors...\")\n",
    "\n",
    "# Initialize DetectionPredictor first, as it's a dependency for RecognitionPredictor [1].\n",
    "detection_predictor = DetectionPredictor() # Used for line-level text detection [2]\n",
    "\n",
    "# Initialize RecognitionPredictor for OCR. It relies on a DetectionPredictor [1].\n",
    "recognition_predictor = RecognitionPredictor() # For OCR [13]\n",
    "\n",
    "# Initialize LayoutPredictor for layout analysis and reading order detection [13].\n",
    "layout_predictor = LayoutPredictor()\n",
    "\n",
    "# Initialize TableRecPredictor for table recognition (detecting rows/columns) [13].\n",
    "table_rec_predictor = TableRecPredictor()\n",
    "\n",
    "print(\"All Surya predictors initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batched processing of 'ANTI_OEDIPUS_FR.pdf'...\n",
      "Total pages in PDF: 451\n",
      "\n",
      "Processing pages 1-10 (Batch 1 of 46)...\n",
      "  Running OCR for pages 1-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 2/2 [00:21<00:00, 10.75s/it]\n",
      "Recognizing Text: 100%|██████████| 215/215 [01:29<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR results saved to surya_batch_results/ocr_results_pages_1_to_10.json\n",
      "  Running Layout Analysis for pages 1-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing layout: 100%|██████████| 3/3 [00:46<00:00, 15.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Layout results saved to surya_batch_results/layout_results_pages_1_to_10.json\n",
      "\n",
      "Processing pages 11-20 (Batch 2 of 46)...\n",
      "  Running OCR for pages 11-20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 2/2 [00:15<00:00,  7.68s/it]\n",
      "Recognizing Text:  21%|██        | 77/369 [01:20<01:02,  4.66it/s] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Starting batched processing of '{os.path.basename(PDF_PATH)}'...\")\n",
    "\n",
    "doc = fitz.open(PDF_PATH)\n",
    "try:\n",
    "    total_pages = len(doc)\n",
    "    print(f\"Total pages in PDF: {total_pages}\")\n",
    "\n",
    "    for batch_num, start_idx in enumerate(range(0, total_pages, BATCH_SIZE), start=1):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, total_pages)\n",
    "        pages   = list(range(start_idx, end_idx))\n",
    "        print(f\"\\nProcessing pages {start_idx+1}-{end_idx} (Batch {batch_num} of {((total_pages + BATCH_SIZE - 1)//BATCH_SIZE)})...\")\n",
    "\n",
    "        # --- Load batch images from PDF ---\n",
    "        batch_images = []\n",
    "        for page_idx in pages:\n",
    "            page = doc.load_page(page_idx)\n",
    "            pix  = page.get_pixmap()\n",
    "            img  = Image.frombytes(\"RGB\", (pix.width, pix.height), pix.samples)\n",
    "            batch_images.append(img)\n",
    "\n",
    "        if not batch_images:\n",
    "            print(f\"  No images for pages {start_idx+1}-{end_idx}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Step 1: OCR ---\n",
    "        print(f\"  Running OCR for pages {start_idx+1}-{end_idx}...\")\n",
    "        rec_preds = recognition_predictor(batch_images, det_predictor=detection_predictor)\n",
    "        ocr_path  = os.path.join(OUTPUT_DIR, f\"ocr_results_pages_{start_idx+1}_to_{end_idx}.json\")\n",
    "        with open(ocr_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump([serialize_surya(p) for p in rec_preds], f, indent=4, ensure_ascii=False)\n",
    "        print(f\"  OCR results saved to {ocr_path}\")\n",
    "\n",
    "        # --- Step 2: Layout Analysis ---\n",
    "        print(f\"  Running Layout Analysis for pages {start_idx+1}-{end_idx}...\")\n",
    "        layout_preds = layout_predictor(batch_images)\n",
    "        layout_path  = os.path.join(OUTPUT_DIR, f\"layout_results_pages_{start_idx+1}_to_{end_idx}.json\")\n",
    "        with open(layout_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump([serialize_surya(p) for p in layout_preds], f, indent=4, ensure_ascii=False)\n",
    "        print(f\"  Layout results saved to {layout_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "finally:\n",
    "    doc.close()\n",
    "\n",
    "print(\"\\nBatched processing complete. Results saved to:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
